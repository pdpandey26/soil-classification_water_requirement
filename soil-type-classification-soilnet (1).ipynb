{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install tensorflow==2.3.0\n!pip install imutils\n!pip install python-telegram-bot #For training updates on Telegram\n\nimport tensorflow as tf\n\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.layers import Dropout, MaxPooling2D, AveragePooling2D, Dense, Flatten, Input, Conv2D, add, Activation\nfrom tensorflow.keras.layers import (Dense, Dropout, Activation, Flatten, Reshape, Layer,\n                          BatchNormalization, LocallyConnected2D,\n                          ZeroPadding2D, Conv2D, MaxPooling2D, Conv2DTranspose,AveragePooling2D,\n                          GaussianNoise, UpSampling2D, Input)\n\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.models import Sequential , Model , load_model\nfrom tensorflow.keras.preprocessing.image import load_img , img_to_array , ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom imutils import paths\nimport numpy as np\nimport os\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Tensorflow version: \",tf.__version__)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_dir = '/kaggle/input/soil-classification-image-data/Soil_Dataset/Train'\ntest_dir = '/kaggle/input/soil-classification-image-data/Soil_Dataset/Test'\n\nimage_size = 224","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                            rotation_range=45,\n                            zoom_range=0.40,\n                            width_shift_range=0.2,\n                            height_shift_range=0.2,\n                            shear_range=0.15,\n                            horizontal_flip=True,\n                            vertical_flip= True,\n                            fill_mode=\"nearest\")\n\ntrain_data = train_datagen.flow_from_directory(train_dir,\n                                              target_size=(150,150),\n                                              batch_size=32,\n                                              class_mode=\"categorical\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale = 1./255)\n\ntest_data = test_datagen.flow_from_directory(test_dir,\n                                            target_size=(150,150),\n                                            batch_size=32,\n                                            class_mode=\"categorical\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n                                                              validation_split = 0.2,\n                                                              subset = \"training\",\n                                                              seed = 42,\n                                                              image_size = (150,150),\n                                                              batch_size = 40)\n\ntest_ds = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n                                                             validation_split = 0.2,\n                                                             subset = \"validation\",\n                                                             seed = 42,\n                                                             image_size = (150,150),\n                                                             batch_size = 40)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Configuring dataset for performance\nAUTOTUNE = tf.data.experimental.AUTOTUNE\ntraining_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\ntesting_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = Sequential(name=\"SoilNet\")\nmodel.add(Conv2D(64,(3,3),activation = \"relu\",padding =\"same\",kernel_initializer=\"he_normal\", input_shape=(150,150,3)))\n#model.add(tf.keras.layers.LeakyReLU())\n#model.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),activation = \"relu\",padding =\"same\",kernel_initializer=\"he_normal\"))\n#model.add(tf.keras.layers.LeakyReLU())\nmodel.add(BatchNormalization())\n\nmodel.add(AveragePooling2D(pool_size = (2,2), strides=2))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(128,(3,3),activation = \"relu\",padding =\"same\",kernel_initializer=\"he_normal\"))\n#model.add(tf.keras.layers.LeakyReLU())\n#model.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3),activation = \"relu\",padding =\"same\",kernel_initializer=\"he_normal\"))\n#model.add(tf.keras.layers.LeakyReLU())\nmodel.add(BatchNormalization())\n\nmodel.add(AveragePooling2D(pool_size = (2,2), strides=2))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\n#lk = tf.keras.layers.LeakyReLU()\nmodel.add(Conv2D(256,(3,3),activation = \"relu\", padding =\"same\",kernel_initializer=\"he_normal\"))\n#model.add(BatchNormalization())\nmodel.add(Conv2D(256,(3,3),activation = \"relu\",padding =\"same\",kernel_initializer=\"he_normal\"))\n#model.add(tf.keras.layers.LeakyReLU())\nmodel.add(BatchNormalization())\n\nmodel.add(AveragePooling2D(pool_size = (2,2), strides=2))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dense(512,activation=\"relu\"))\nmodel.add(Dropout(0.7))\nmodel.add(Dense(4,activation=\"softmax\"))\n\nopt = RMSprop(learning_rate = 0.0001, rho = 0.99, epsilon = 1e-08, decay = 0.0)\nmodel.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n\nreduction_lr = ReduceLROnPlateau(monitor = \"val_accuracy\",patience = 2 ,verbose = 1, factor = 0.3, min_lr = 0.0000001)\nreduction_lr1 = ReduceLROnPlateau(monitor = \"val_loss\",patience = 2 ,verbose = 1, factor = 0.3, min_lr = 0.0000001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#bot_callback = botCallback(access_token)\n#plotter = Plotter(access_token)\n#callback_list = [bot_callback,plotter] callbacks=callback_list\n\nstart = time.time()\n\nhistory = model.fit_generator(train_data,\n                    validation_data = test_data,\n                    epochs=20,\n                    callbacks = [reduction_lr,reduction_lr1])\nend = time.time()\nprint(\"Total train time: \",(end-start)/60,\" mins\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_graph(history,string):\n    plt.figure(figsize=(12,8))\n    plt.plot(history.history[string],label=str(string))\n    plt.plot(history.history[\"val_\"+str(string)],label=\"val_\"+str(string))\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(str(string))\n    plt.legend()\n    plt.show()\nplot_graph(history,\"accuracy\")\nplot_graph(history,\"loss\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"SoilNet.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('SoilNet.h5')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}